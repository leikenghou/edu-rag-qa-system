import os
import logging
import hashlib
import shutil
import tempfile
from datetime import datetime
from typing import Optional, List, Dict, Any
from langchain_core.documents import Document
import streamlit as st
from dotenv import load_dotenv
from langchain_community.chat_models import ChatOpenAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
from sentence_transformers import SentenceTransformer

# ==================== é…ç½®å¸¸é‡ ====================
CHUNK_SIZE = 500
CHUNK_OVERLAP = 50
VECTOR_SEARCH_K = 5
BM25_SEARCH_K = 5
DEFAULT_VECTOR_WEIGHT = 0.5
PAGE_SIZE = 5
VECTOR_STORE_DIR = "./chroma_db"  # ä¿®æ”¹ä¸ºæ›´æ˜ç¡®çš„ç›®å½•å

# ==================== åˆå§‹åŒ–è®¾ç½® ====================
# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# ç»•è¿‡ Streamlit/PyTorch é”™è¯¯
os.environ["STREAMLIT_SERVER_FILE_WATCHER_TYPE"] = "none"

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
deepseek_api_key = os.getenv("API_KEY")
base_url = "https://api.deepseek.com"


# ==================== Session State åˆå§‹åŒ– ====================
def initialize_session_state():
    """ç¡®ä¿æ‰€æœ‰éœ€è¦çš„ session state å˜é‡éƒ½å·²åˆå§‹åŒ–"""
    required_states = {
        "processed_files": set(),
        "all_docs": [],
        "bm25_retriever": None,
        "ensemble_retriever": None,
        "vector_weight": DEFAULT_VECTOR_WEIGHT,
        "vectorstore": None,
        "embeddings": None,
        "retrieval_mode": "æ··åˆæ£€ç´¢",
        "last_refresh_time": None,
        "current_page": 1,
        "last_question": "",
        "last_answer": "",
        "last_context": []
    }

    for key, default_value in required_states.items():
        if key not in st.session_state:
            st.session_state[key] = default_value


# åˆå§‹åŒ–session state
initialize_session_state()


# ==================== æ¨¡å‹åˆå§‹åŒ– ====================
@st.cache_resource
def initialize_models():
    """åˆå§‹åŒ–è¯­è¨€æ¨¡å‹å’ŒåµŒå…¥æ¨¡å‹"""
    try:
        # åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
        llm = ChatOpenAI(
            model="deepseek-chat",
            openai_api_key=deepseek_api_key,
            base_url=base_url,
            temperature=0.7
        )

        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        model_name = "BAAI/bge-m3"
        embeddings = HuggingFaceEmbeddings(
            model_name=model_name,
            model_kwargs={"device": "cpu"},
            encode_kwargs={"normalize_embeddings": True}
        )

        return llm, embeddings
    except Exception as e:
        logger.error(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        st.error(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        st.stop()


# ==================== å‘é‡æ•°æ®åº“åˆå§‹åŒ– ====================
@st.cache_resource
def initialize_vectorstore(_embeddings, persist_directory=VECTOR_STORE_DIR):
    """åˆå§‹åŒ–æˆ–é‡å»ºå‘é‡æ•°æ®åº“"""
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(persist_directory, exist_ok=True)

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®åº“
        collection_files = [
            "chroma-collections.parquet",
            "chroma-embeddings.parquet"
        ]
        db_exists = all(os.path.exists(os.path.join(persist_directory, f)) for f in collection_files)

        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        vectorstore = Chroma(
            persist_directory=persist_directory,
            embedding_function=_embeddings
        )

        # åˆå§‹åŒ–session stateä¸­çš„æ–‡æ¡£åˆ—è¡¨
        if len(st.session_state.all_docs) == 0 and db_exists:
            try:
                # ä»æ•°æ®åº“åŠ è½½å·²æœ‰æ–‡æ¡£
                db_content = vectorstore.get()
                if db_content and "documents" in db_content and len(db_content["documents"]) > 0:
                    st.session_state.all_docs = [
                        Document(
                            page_content=doc,
                            metadata=db_content["metadatas"][i] if "metadatas" in db_content else {}
                        )
                        for i, doc in enumerate(db_content["documents"])
                    ]
                    logger.info(f"ä»æ•°æ®åº“åŠ è½½äº† {len(st.session_state.all_docs)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")

                    # åˆå§‹åŒ–å·²å¤„ç†æ–‡ä»¶é›†åˆ
                    for doc in st.session_state.all_docs:
                        if "source" in doc.metadata:
                            file_hash = hashlib.md5(doc.metadata["source"].encode()).hexdigest()
                            st.session_state.processed_files.add(file_hash)
            except Exception as e:
                logger.warning(f"åŠ è½½å·²æœ‰æ–‡æ¡£å¤±è´¥: {str(e)}")

        return vectorstore
    except Exception as e:
        logger.error(f"å‘é‡æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        st.error(f"å‘é‡æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        st.stop()


# åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
try:
    llm, embeddings = initialize_models()
    vectorstore = initialize_vectorstore(embeddings)
    st.session_state.vectorstore = vectorstore
    st.session_state.embeddings = embeddings

    # åˆå§‹åŒ–BM25æ£€ç´¢å™¨
    if len(st.session_state.all_docs) > 0:
        st.session_state.bm25_retriever = BM25Retriever.from_documents(
            st.session_state.all_docs
        )
        st.session_state.bm25_retriever.k = BM25_SEARCH_K
except Exception as e:
    st.error("ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶åˆ·æ–°é¡µé¢")
    st.stop()

# ==================== æ£€ç´¢ç³»ç»Ÿè®¾ç½® ====================
vector_retriever = vectorstore.as_retriever(search_kwargs={"k": VECTOR_SEARCH_K})

# æç¤ºæ¨¡æ¿
prompt_template = """
ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†é—®ç­”åŠ©æ‰‹ã€‚æ ¹æ®ä»¥ä¸‹æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œå›ç­”è¦ç®€æ´ã€å‡†ç¡®ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸è¶³ä»¥å›ç­”ï¼Œè¯´æ˜æ— æ³•å›ç­”å¹¶å»ºè®®ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯ã€‚æ¥ç€ä½¿ç”¨deepseekçš„çŸ¥è¯†è¿›è¡Œå›ç­”ï¼ˆéœ€è¦æ˜ç¡®æŒ‡å‡ºï¼‰ã€‚

**ä¸Šä¸‹æ–‡**ï¼š
{context}

**é—®é¢˜**ï¼š
{question}

**å›ç­”**ï¼š
"""
prompt = PromptTemplate.from_template(prompt_template)


# ==================== æ£€ç´¢å™¨é€»è¾‘ ====================
def get_retriever(_=None):
    """æ ¹æ®å½“å‰è®¾ç½®è¿”å›é€‚å½“çš„æ£€ç´¢å™¨"""
    initialize_session_state()

    retrieval_mode = st.session_state.retrieval_mode
    vector_weight = st.session_state.vector_weight

    if retrieval_mode == "ä»…å‘é‡æ£€ç´¢":
        return vector_retriever

    if retrieval_mode == "ä»…å…³é”®å­—æ£€ç´¢(BM25)":
        if st.session_state.bm25_retriever is None and st.session_state.all_docs:
            try:
                st.session_state.bm25_retriever = BM25Retriever.from_documents(
                    st.session_state.all_docs
                )
                st.session_state.bm25_retriever.k = BM25_SEARCH_K
            except Exception as e:
                logger.error(f"åˆ›å»ºBM25æ£€ç´¢å™¨å¤±è´¥: {str(e)}")
                return vector_retriever
        return st.session_state.bm25_retriever or vector_retriever

    # æ··åˆæ£€ç´¢æ¨¡å¼
    if st.session_state.bm25_retriever is None and st.session_state.all_docs:
        try:
            st.session_state.bm25_retriever = BM25Retriever.from_documents(
                st.session_state.all_docs
            )
            st.session_state.bm25_retriever.k = BM25_SEARCH_K
        except Exception as e:
            logger.error(f"åˆ›å»ºBM25æ£€ç´¢å™¨å¤±è´¥: {str(e)}")
            return vector_retriever

    if st.session_state.bm25_retriever:
        return EnsembleRetriever(
            retrievers=[vector_retriever, st.session_state.bm25_retriever],
            weights=[vector_weight, 1.0 - vector_weight]
        )
    return vector_retriever


# ==================== RAG é“¾ ====================
def format_docs(docs):
    """å°†æ–‡æ¡£åˆ—è¡¨æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²"""
    return "\n".join(doc.page_content for doc in docs)

# ä¿®æ”¹åçš„RAGé“¾
rag_chain = (
    {
        "context": RunnableLambda(get_retriever) | RunnableLambda(format_docs),
        "question": RunnablePassthrough()
    }
    | prompt
    | llm
    | StrOutputParser()
)


# ==================== PDF å¤„ç†å‡½æ•° ====================
def process_pdf_file(uploaded_file):
    """å¤„ç†ä¸Šä¼ çš„ PDF æ–‡ä»¶å¹¶æ›´æ–°çŸ¥è¯†åº“"""
    tmp_file_path = None
    try:
        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        file_content = uploaded_file.read()
        file_hash = hashlib.md5(file_content).hexdigest()
        uploaded_file.seek(0)

        # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
        if file_hash in st.session_state.processed_files:
            st.warning("æ­¤ PDF æ–‡ä»¶å·²ä¸Šä¼ å¹¶å¤„ç†ï¼Œè·³è¿‡é‡å¤åµŒå…¥ã€‚")
            return

        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(file_content)
            tmp_file_path = tmp_file.name

        # åŠ è½½å’ŒéªŒè¯ PDF
        loader = PyPDFLoader(tmp_file_path)
        documents = loader.load()

        if not documents or not any(doc.page_content.strip() for doc in documents):
            raise ValueError("PDF æ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–ä¸å¯è¯»ï¼")

        # åˆ†å‰²æ–‡æœ¬
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=CHUNK_SIZE,
            chunk_overlap=CHUNK_OVERLAP
        )
        splits = text_splitter.split_documents(documents)

        # ä¸ºæ¯ä¸ªç‰‡æ®µæ·»åŠ æºæ–‡ä»¶ä¿¡æ¯
        for split in splits:
            split.metadata["source"] = uploaded_file.name

        # æ›´æ–°å‘é‡æ•°æ®åº“ (Chromaä¼šè‡ªåŠ¨æŒä¹…åŒ–)
        st.session_state.vectorstore.add_documents(splits)

        # æ›´æ–°å†…å­˜ä¸­çš„æ–‡æ¡£åˆ—è¡¨
        st.session_state.all_docs.extend(splits)
        st.session_state.processed_files.add(file_hash)

        # é‡å»º BM25 æ£€ç´¢å™¨
        try:
            st.session_state.bm25_retriever = BM25Retriever.from_documents(
                st.session_state.all_docs
            )
            st.session_state.bm25_retriever.k = BM25_SEARCH_K
        except Exception as e:
            logger.error(f"æ›´æ–°BM25æ£€ç´¢å™¨å¤±è´¥: {str(e)}")

        st.session_state.last_refresh_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        st.success(f"æˆåŠŸå¤„ç† {uploaded_file.name}ï¼æ–°å¢ {len(splits)} ä¸ªæ–‡æ¡£ç‰‡æ®µã€‚")
    except Exception as e:
        logger.error(f"å¤„ç† PDF æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        st.error(f"å¤„ç† PDF æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    finally:
        if tmp_file_path and os.path.exists(tmp_file_path):
            os.unlink(tmp_file_path)


# ==================== ä¾§è¾¹æ çŸ¥è¯†åº“æŸ¥çœ‹ ====================
def knowledge_base_sidebar():
    """ä¾§è¾¹æ çŸ¥è¯†åº“æŸ¥çœ‹åŠŸèƒ½"""
    with st.sidebar:
        st.header("ğŸ“š çŸ¥è¯†åº“ç®¡ç†")

        # ç‹¬ç«‹åˆ·æ–°æŒ‰é’®
        if st.button("ğŸ”„ åˆ·æ–°çŸ¥è¯†åº“", use_container_width=True, help="ä»ç£ç›˜é‡æ–°åŠ è½½æ‰€æœ‰å†…å®¹"):
            try:
                # é‡æ–°åˆå§‹åŒ–å‘é‡æ•°æ®åº“
                st.session_state.vectorstore = Chroma(
                    persist_directory=VECTOR_STORE_DIR,
                    embedding_function=st.session_state.embeddings
                )

                # é‡æ–°åŠ è½½æ–‡æ¡£
                db_content = st.session_state.vectorstore.get()
                st.session_state.all_docs = [
                    Document(
                        page_content=doc,
                        metadata=db_content["metadatas"][i] if "metadatas" in db_content else {}
                    )
                    for i, doc in enumerate(db_content["documents"])
                ] if "documents" in db_content else []

                # é‡å»ºå·²å¤„ç†æ–‡ä»¶é›†åˆ
                st.session_state.processed_files = set()
                for doc in st.session_state.all_docs:
                    if "source" in doc.metadata:
                        file_hash = hashlib.md5(doc.metadata["source"].encode()).hexdigest()
                        st.session_state.processed_files.add(file_hash)

                # é‡å»ºBM25æ£€ç´¢å™¨
                if len(st.session_state.all_docs) > 0:
                    st.session_state.bm25_retriever = BM25Retriever.from_documents(
                        st.session_state.all_docs
                    )
                    st.session_state.bm25_retriever.k = BM25_SEARCH_K

                st.session_state.last_refresh_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                st.rerun()
            except Exception as e:
                st.error(f"åˆ·æ–°çŸ¥è¯†åº“å¤±è´¥: {str(e)}")

        if st.session_state.last_refresh_time:
            st.caption(f"æœ€ååˆ·æ–°: {st.session_state.last_refresh_time}")

        # çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯
        st.divider()
        st.markdown(f"**æ–‡æ¡£ç‰‡æ®µæ€»æ•°**: {len(st.session_state.all_docs)}")
        st.markdown(f"**å·²å¤„ç†æ–‡ä»¶æ•°**: {len(st.session_state.processed_files)}")

        # åˆ†é¡µæ§åˆ¶
        st.divider()
        total_pages = max(1, (len(st.session_state.all_docs) + PAGE_SIZE - 1) // PAGE_SIZE)
        st.session_state.current_page = st.number_input(
            "é¡µç ",
            min_value=1,
            max_value=total_pages,
            value=st.session_state.current_page,
            key="kb_page_input"
        )

        # æ–‡æ¡£æ˜¾ç¤º
        st.divider()
        if not st.session_state.all_docs:
            st.info("çŸ¥è¯†åº“ä¸ºç©ºï¼Œè¯·ä¸Šä¼ PDFæ–‡ä»¶")
            return

        start_idx = (st.session_state.current_page - 1) * PAGE_SIZE
        end_idx = min(start_idx + PAGE_SIZE, len(st.session_state.all_docs))

        for i in range(start_idx, end_idx):
            doc = st.session_state.all_docs[i]
            with st.expander(f"ğŸ“„ ç‰‡æ®µ {i + 1}", expanded=False):
                st.markdown(f"**æ¥æº**: `{doc.metadata.get('source', 'æœªçŸ¥')}`")
                st.markdown(f"**é¡µç **: {doc.metadata.get('page', 'æœªçŸ¥')}")
                st.markdown("**å†…å®¹é¢„è§ˆ**:")
                st.text(doc.page_content[:150] + ("..." if len(doc.page_content) > 150 else ""))
                if st.checkbox("æ˜¾ç¤ºå®Œæ•´å†…å®¹", key=f"full_{i}"):
                    st.text_area("å†…å®¹", doc.page_content, height=200, key=f"content_{i}", label_visibility="collapsed")


# ==================== ä¸»ç•Œé¢ ====================
def main_interface():
    """ä¸»ç•Œé¢åŠŸèƒ½"""
    st.title("ğŸ§  RAG çŸ¥è¯†é—®ç­”ç³»ç»Ÿ")
    st.caption("Powered by DeepSeek & LangChain")

    # æ£€ç´¢è®¾ç½®
    with st.expander("âš™ï¸ æ£€ç´¢é…ç½®", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.selectbox(
                "æ£€ç´¢æ¨¡å¼",
                ["æ··åˆæ£€ç´¢", "ä»…å‘é‡æ£€ç´¢", "ä»…å…³é”®å­—æ£€ç´¢(BM25)"],
                key="retrieval_mode"
            )
        with col2:
            st.slider(
                "å‘é‡æƒé‡",
                0.0, 1.0, DEFAULT_VECTOR_WEIGHT,
                key="vector_weight"
            )

    # æ–‡ä»¶ä¸Šä¼ 
    with st.expander("ğŸ“¤ ä¸Šä¼ æ–‡æ¡£", expanded=False):
        uploaded_file = st.file_uploader(
            "é€‰æ‹©PDFæ–‡ä»¶",
            type=["pdf"],
            label_visibility="collapsed"
        )
        if uploaded_file is not None:
            with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
                process_pdf_file(uploaded_file)

    # é—®ç­”åŒºåŸŸ
    st.divider()
    question = st.text_input(
        "ğŸ’¡ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š",
        placeholder="è¾“å…¥é—®é¢˜åæŒ‰å›è½¦æŸ¥è¯¢",
        key="question_input"
    )

    if question:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°ç”Ÿæˆå›ç­”
        if ("last_question" not in st.session_state or
                st.session_state.last_question != question or
                "last_answer" not in st.session_state):

            with st.spinner("æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“å¹¶ç”Ÿæˆå›ç­”..."):
                try:
                    # è·å–ä¸Šä¸‹æ–‡
                    retriever = get_retriever()
                    docs = retriever.invoke(question)

                    # ç”Ÿæˆå›ç­” - è¿™é‡Œç›´æ¥ä¼ é€’é—®é¢˜å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯å­—å…¸
                    answer = rag_chain.invoke(question)

                    # å­˜å‚¨ç»“æœ
                    st.session_state.last_question = question
                    st.session_state.last_answer = answer
                    st.session_state.last_context = docs
                except Exception as e:
                    st.error(f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}")
                    return

        # æ˜¾ç¤ºå›ç­”
        st.markdown("### å›ç­”")
        st.write(st.session_state.last_answer)

        # æ˜¾ç¤ºä¸Šä¸‹æ–‡ï¼ˆä¸éœ€è¦é‡æ–°è®¡ç®—ï¼‰
        if st.checkbox("æ˜¾ç¤ºç›¸å…³ä¸Šä¸‹æ–‡", key="show_context"):
            st.markdown("### ç›¸å…³ä¸Šä¸‹æ–‡")
            for i, doc in enumerate(st.session_state.last_context, 1):
                st.markdown(f"#### ä¸Šä¸‹æ–‡ {i}")
                st.markdown(f"**æ¥æº**: `{doc.metadata.get('source', 'æœªçŸ¥')}`")
                st.markdown(f"**é¡µç **: {doc.metadata.get('page', 'æœªçŸ¥')}")
                st.text(doc.page_content)


# ==================== åº”ç”¨å…¥å£ ====================
if __name__ == "__main__":
    # ç¡®ä¿session stateå·²åˆå§‹åŒ–
    initialize_session_state()

    # åŠ è½½ç•Œé¢
    knowledge_base_sidebar()
    main_interface()